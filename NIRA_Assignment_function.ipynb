{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd # for data handling\n",
    "import numpy as np # for mathematical calculations\n",
    "import seaborn as sns # for data visualisations\n",
    "import matplotlib.pyplot as plt # for plotting graphs\n",
    "%matplotlib inline\n",
    "import warnings # to ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Data\n",
    "data = pd.read_csv(\"data_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    \n",
    "    \"\"\" \n",
    "    this function is used to preprocess the dataset, starting from filling missing values to Outlier Treatment \n",
    "    \n",
    "    Parameters: \n",
    "    df (DataFrame): input dataset for training \n",
    "  \n",
    "    Returns: \n",
    "    DataFrame: preprocessed dataset \n",
    "  \n",
    "    \"\"\"\n",
    "    \n",
    "    # Missing Value Treatment\n",
    "    df[\"Gender\"].fillna(df[\"Gender\"].mode()[0],inplace=True)\n",
    "    df[\"Married\"].fillna(df[\"Married\"].mode()[0],inplace=True)\n",
    "    df['Dependents'].fillna(df[\"Dependents\"].mode()[0],inplace=True)\n",
    "    df[\"Self_Employed\"].fillna(df[\"Self_Employed\"].mode()[0],inplace=True)\n",
    "    df[\"Credit_History\"].fillna(df[\"Credit_History\"].mode()[0],inplace=True)\n",
    "    \n",
    "    df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].mode()[0], inplace=True)\n",
    "    \n",
    "    df['LoanAmount'].fillna(df['LoanAmount'].median(), inplace=True)\n",
    "    \n",
    "    # Outlier Treatment\n",
    "    df['LoanAmount_log_transformed'] = np.log(df['LoanAmount'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocess(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    \"\"\"\n",
    "    this function creates new features from exisiting features which could be highly important for model learning purpose\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): input dataset \n",
    "    \n",
    "    Returns: \n",
    "    DataFrame: dataset with new features\n",
    "  \n",
    "    \"\"\"\n",
    "    \n",
    "    df[\"TotalIncome\"] = df[\"ApplicantIncome\"] + df[\"CoapplicantIncome\"]\n",
    "    df['TotalIncome_log_transformed'] = np.log(df['TotalIncome']) \n",
    "    df[\"EMI\"] = df[\"LoanAmount\"]/df[\"Loan_Amount_Term\"]\n",
    "    df[\"Balance_Income\"] = df[\"TotalIncome\"]-df[\"EMI\"]*1000 # To make the units equal we multiply with 1000\n",
    "    \n",
    "    df = df.drop([\"ApplicantIncome\",\"CoapplicantIncome\",\"LoanAmount\",\"Loan_Amount_Term\", \"TotalIncome\"],axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = feature_engineering(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparing_dataset_for_training(df):\n",
    "    \"\"\"\n",
    "    this function make a dataset ready for model training and performs Encoding and required Splitting\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): input dataset\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: dataset for model training\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.drop(\"Loan_ID\",axis=1)\n",
    "    X=df.drop(\"Loan_Status\",1)\n",
    "    y=df[[\"Loan_Status\"]]\n",
    "    \n",
    "    # Converting the Categorical Variables into Numericals\n",
    "    X = pd.get_dummies(X)\n",
    "    X1=X # later to be used for feature importance labels\n",
    "    \n",
    "    # Feature Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X = sc.fit_transform(X)\n",
    "    \n",
    "    # Splitting the Dataset into Training and Test set\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=1)\n",
    "    \n",
    "    return x_train,x_test,y_train,y_test, X, y, X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test, X, y, X1 = preparing_dataset_for_training(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Training on Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Logistic Regression model on the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier_lr = LogisticRegression(C= 0.1, penalty = 'l1', random_state = 0) \n",
    "classifier_lr.fit(x_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred_lr = classifier_lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_validation(df, classifier, y_pred, x_train, y_train):\n",
    "    \"\"\"\n",
    "    this function is responsible for applying cross validation and Grid Search to find a robust model accuracy\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): input dataset\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: dataset and prints the optimal parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    # Applying k-fold cross validation\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n",
    "    \n",
    "    # Using Grid Search to find optimal parameters\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    parameters = [{\"C\":[0.001, 0.01, 0.1, 1, 10, 100], \"penalty\":[\"l1\",\"l2\"]}]# l1 lasso l2 ridge]\n",
    "    grid_search = GridSearchCV(estimator = classifier,\n",
    "                               param_grid = parameters,\n",
    "                               scoring = 'accuracy',\n",
    "                               cv = 10,\n",
    "                               n_jobs = -1)\n",
    "    grid_search = grid_search.fit(x_train, y_train)\n",
    "    best_accuracy = grid_search.best_score_\n",
    "    best_parameters = grid_search.best_params_\n",
    "    print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
    "    print(\"Best Parameters:\", best_parameters)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.82 %\n",
      "Standard Deviation: 3.06 %\n",
      "Best Accuracy: 81.82 %\n",
      "Best Parameters: {'C': 0.1, 'penalty': 'l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shubhamsunwalka/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "data = model_validation(data, classifier_lr, y_pred_lr, x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
